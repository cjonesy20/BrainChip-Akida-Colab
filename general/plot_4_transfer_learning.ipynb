{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://doc.brainchipinc.com/_downloads/0792bc3dc7b01941f86b4f993c20ab5f/requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Transfer learning with AkidaNet for PlantVillage\n",
        "\n",
        "This tutorial presents how to perform transfer learning for quantized models targeting an Akida\n",
        "accelerator.\n",
        "\n",
        "The transfer learning example is derived from the [Tensorflow tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning)_ where the\n",
        "base model is an AkidaNet 0.5 quantized model trained on ImageNet and the\n",
        "target dataset is [PlantVillage](https://www.tensorflow.org/datasets/catalog/plant_village)_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer learning process\n",
        "\n",
        "Transfer learning consists in customizing a pretrained model or feature\n",
        "extractor to fit another task.\n",
        "\n",
        "**Base model**\n",
        "\n",
        "The base model is an AkidaNet 0.5 that was trained on the\n",
        "ImageNet dataset. Please refer to the [dedicated example](plot_1_akidanet_imagenet.html)_ for more information on the model\n",
        "architecture and performance.\n",
        "\n",
        "**Classification head**\n",
        "\n",
        "Customization of the model happens by adding layers on top of the base model,\n",
        "which in AkidaNet case ends with a global average operation.\n",
        "\n",
        "The classification head is typically composed of two dense layers as follows:\n",
        "\n",
        "  - the first dense layer number of units is configurable and depends on the\n",
        "    task but is generally 512 or below,\n",
        "  - a BatchNormalization operation and ReLU activation follow the first layer,\n",
        "  - a dropout layer is placed between the two dense layers to prevent\n",
        "    overfitting,\n",
        "  - the second dense layer is the prediction layer and should have its units\n",
        "    value set to the number of classes to predict,\n",
        "  - a softmax activation ends the model.\n",
        "\n",
        "**Training process**\n",
        "\n",
        "The standard training process for transfer learning for AkidaNet is:\n",
        "\n",
        "  1. Get a trained float AkidaNet base model\n",
        "  2. Add a classification head to the model\n",
        "  3. Tune the whole model for a few epochs\n",
        "  4. Quantize the whole model\n",
        "  5. Optionally perform QAT for a few epochs to recover accuracy\n",
        "\n",
        "The transfer learning process operates in float precision,\n",
        "ensuring seamless integration with users' existing familiarity in setting\n",
        "hyperparameters, adding a new head, and deciding on layer freezing.\n",
        "\n",
        "While this process will apply to most of the tasks, there might be cases where\n",
        "variants are needed:\n",
        "\n",
        "  - Quantization in the 4th step might lead to drop in accuracy (especially for 4\n",
        "    bits quantization). In such a case, an additional step of fine tuning is needed\n",
        "    and consists in training for a few additional epochs with a lower learning rate\n",
        "    (e.g 10 to 100 times lower than the initial rate).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset preparation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Define task specific variables\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "CLASSES = 38\n",
        "\n",
        "# Load the tensorflow dataset\n",
        "(train_ds, validation_ds, test_ds), ds_info = tfds.load(\n",
        "    'plant_village',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True)\n",
        "\n",
        "# Visualize some data\n",
        "_ = tfds.show_examples(test_ds, ds_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Format test data\n",
        "def format_example(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image, label\n",
        "\n",
        "\n",
        "test_batches = test_ds.map(format_example).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get a trained AkidaNet base model\n",
        "\n",
        "The AkidaNet architecture is available in the Akida model zoo as\n",
        "[akidanet_imagenet](../../api_reference/akida_models_apis.html#akida_models.akidanet_imagenet).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models import fetch_file, akidanet_imagenet\n",
        "\n",
        "# Create a base model without top layers\n",
        "base_model = akidanet_imagenet(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                               classes=CLASSES,\n",
        "                               alpha=0.5,\n",
        "                               include_top=False,\n",
        "                               pooling='avg')\n",
        "\n",
        "# Get pretrained quantized weights and load them into the base model\n",
        "pretrained_weights = fetch_file(\n",
        "    origin=\"https://data.brainchip.com/models/AkidaV2/akidanet/akidanet_imagenet_224_alpha_0.5.h5\",\n",
        "    fname=\"akidanet_imagenet_224_alpha_0.5.h5\",\n",
        "    cache_subdir='models')\n",
        "\n",
        "base_model.load_weights(pretrained_weights, by_name=True)\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Add a classification head to the model\n",
        "\n",
        "As explained in [section 1](#transfer-learning-process)_, the classification\n",
        "head is defined as a dense layer with batch normalization and activation,\n",
        "which correspond to a [dense_block](../../api_reference/akida_models_apis.html#akida_models.layer_blocks.dense_block)_, followed by\n",
        "a dropout layer and a second dense layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Activation, Dropout, Reshape\n",
        "from akida_models.layer_blocks import dense_block\n",
        "\n",
        "x = base_model.output\n",
        "x = dense_block(x,\n",
        "                units=512,\n",
        "                name='fc1',\n",
        "                add_batchnorm=True,\n",
        "                relu_activation='ReLU7.5')\n",
        "x = Dropout(0.5, name='dropout_1')(x)\n",
        "x = dense_block(x,\n",
        "                units=CLASSES,\n",
        "                name='predictions',\n",
        "                add_batchnorm=False,\n",
        "                relu_activation=False)\n",
        "x = Activation('softmax', name='act_softmax')(x)\n",
        "x = Reshape((CLASSES,), name='reshape')(x)\n",
        "\n",
        "# Build the model\n",
        "model_keras = Model(base_model.input, x, name='akidanet_plantvillage')\n",
        "\n",
        "model_keras.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train for a few epochs\n",
        "\n",
        "Only giving textual information for training in this tutorial:\n",
        "\n",
        "  - the model is compiled with an Adam optimizer and the sparse categorical\n",
        "    crossentropy loss is used,\n",
        "  - the initial learning rate is set to 1e-3 and ends at 1e-5 with an exponential decay,\n",
        "  - the training lasts for 10 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Quantize the model\n",
        "\n",
        "Quantization is done using QuantizeML [quantize](../../api_reference/quantizeml_apis.html#quantizeml.models.quantize)_.\n",
        "\n",
        "In order to get the best possible model, calibration samples should be provided to the model.\n",
        "Using here samples from the train set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from quantizeml.models import quantize\n",
        "from quantizeml.layers import QuantizationParams\n",
        "\n",
        "train_batches = train_ds.map(format_example).batch(BATCH_SIZE)\n",
        "\n",
        "# Prepare a quantization scheme: first layer weights to 8-bit, other weights and activation to 4-bit\n",
        "qparams = QuantizationParams(input_weight_bits=8, weight_bits=4, activation_bits=4)\n",
        "\n",
        "# Quantize the model, using the 1024 calibration samples from the train set and calibrate over 2\n",
        "# epochs with a batch_size of 100.\n",
        "model_quantized = quantize(model_keras, qparams=qparams,\n",
        "                           samples=train_batches, epochs=2, batch_size=BATCH_SIZE, num_samples=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To recover the loss of accuracy introduced with 4-bit quantization, an extra QAT step with a lower\n",
        "learning rate (training rate divided by 10) is required. Note that you could also aim for 8-bit\n",
        "quantization and not require this extra QAT step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compute accuracy\n",
        "\n",
        "Because training is not included in this tutorial, the pretrained Keras model\n",
        "is retrieved from the zoo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models import akidanet_plantvillage_pretrained\n",
        "\n",
        "model = akidanet_plantvillage_pretrained()\n",
        "\n",
        "# Evaluate Keras accuracy\n",
        "model.compile(metrics=['accuracy'])\n",
        "history = model.evaluate(test_batches, verbose=0)\n",
        "print('Keras accuracy: ', history[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert the model and evaluate the Akida model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from cnn2snn import convert\n",
        "\n",
        "model_akida = convert(model)\n",
        "\n",
        "# Manual evaluation loop to retrieve activations and labels\n",
        "labels, logits = None, None\n",
        "for batch, label_batch in test_batches:\n",
        "    logits_batch = model_akida.predict(batch.numpy().astype('uint8'))\n",
        "\n",
        "    if labels is None:\n",
        "        labels = label_batch\n",
        "        logits = logits_batch.squeeze(axis=(1, 2))\n",
        "    else:\n",
        "        labels = np.concatenate((labels, label_batch))\n",
        "        logits = np.concatenate((logits, logits_batch.squeeze(axis=(1, 2))))\n",
        "preds = Activation(\"softmax\")(logits)\n",
        "accuracy = (np.argmax(preds, 1) == labels).mean()\n",
        "\n",
        "print(f\"Akida accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
