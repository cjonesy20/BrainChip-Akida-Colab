{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://doc.brainchipinc.com/_downloads/0792bc3dc7b01941f86b4f993c20ab5f/requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Akida vision edge learning\n",
        "\n",
        "This tutorial demonstrates the Akida NSoC **edge learning** capabilities using\n",
        "its built-in learning algorithm.\n",
        "It focuses on an image classification example, where an existing Akida network\n",
        "is re-trained to be able to classify images from 4 new classes.\n",
        "\n",
        "Just a few samples (few-shot learning) of the new classes are sufficient\n",
        "to augment the Akida model with extra classes, while preserving high accuracy.\n",
        "\n",
        "Please refer to the [keyword spotting (KWS) tutorial](plot_1_edge_learning_kws.html)_\n",
        "for edge learning documentation, parameters fine tuning and steps details.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida import FullyConnected\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Retrieve TensorFlow `coil100 <https://www.tensorflow.org/datasets/catalog/coil100>`__\n",
        "# dataset\n",
        "ds, ds_info = tfds.load('coil100:2.*.*', split='train', with_info=True)\n",
        "print(ds_info.description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Select the 4 cup objects that will be used as new classes\n",
        "object_ids = [15, 17, 24, 42]\n",
        "object_dict = {k: [] for k in object_ids}\n",
        "for data in ds:\n",
        "    object_id = data['object_id'].numpy()\n",
        "    if object_id in object_dict.keys():\n",
        "        object_dict[object_id].append(data['image'].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display one image per selected object\n",
        "f, axarr = plt.subplots(1, len(object_dict))\n",
        "i = 0\n",
        "for k in object_dict:\n",
        "    axarr[i].axis('off')\n",
        "    axarr[i].imshow(object_dict[k][0])\n",
        "    axarr[i].set_title(k, fontsize=10)\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Akida model for learning\n",
        "\n",
        ".. Note:: Edge learning is only supported for Akida 1.0 models for now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida_models import akidanet_edge_imagenet_pretrained\n",
        "from cnn2snn import convert, set_akida_version, AkidaVersion\n",
        "\n",
        "# Load a pre-trained model\n",
        "with set_akida_version(AkidaVersion.v1):\n",
        "    model_keras = akidanet_edge_imagenet_pretrained()\n",
        "\n",
        "# Convert it to Akida\n",
        "model_ak = convert(model_keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from akida import AkidaUnsupervised\n",
        "\n",
        "# Replace the last layer by a classification layer\n",
        "num_classes = len(object_dict)\n",
        "num_neurons_per_class = 1\n",
        "num_weights = 350\n",
        "model_ak.pop_layer()\n",
        "layer_fc = FullyConnected(name='akida_edge_layer',\n",
        "                          units=num_classes * num_neurons_per_class,\n",
        "                          activation=False)\n",
        "model_ak.add(layer_fc)\n",
        "model_ak.compile(optimizer=AkidaUnsupervised(num_weights=num_weights,\n",
        "                                             num_classes=num_classes,\n",
        "                                             learning_competition=0.1))\n",
        "model_ak.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Edge learning with Akida\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.image import resize_with_crop_or_pad\n",
        "from time import time\n",
        "\n",
        "# Learn objects in num_shots shot(s)\n",
        "num_shots = 1\n",
        "for i in range(len(object_ids)):\n",
        "    start = time()\n",
        "    train_images = object_dict[object_ids[i]][:num_shots]\n",
        "    for image in train_images:\n",
        "        padded_image = resize_with_crop_or_pad(image, 224, 224)\n",
        "        model_ak.fit(np.expand_dims(padded_image, axis=0), i)\n",
        "    end = time()\n",
        "    print(f'Learned object {object_ids[i]} (class {i}) with \\\n",
        "            {len(train_images)} sample(s) in {end-start:.2f}s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import statistics as stat\n",
        "\n",
        "# Check accuracy against remaining samples\n",
        "accuracy = []\n",
        "for i in range(len(object_ids)):\n",
        "    test_images = object_dict[object_ids[i]][num_shots:]\n",
        "    predictions = np.zeros(len(test_images))\n",
        "    for j in range(len(test_images)):\n",
        "        padded_image = resize_with_crop_or_pad(test_images[j], 224, 224)\n",
        "        predictions[j] = model_ak.predict_classes(np.expand_dims(padded_image,\n",
        "                                                                 axis=0),\n",
        "                                                  num_classes=num_classes)\n",
        "    accuracy.append(100 * np.sum(predictions == i) / len(test_images))\n",
        "    print(f'Accuracy testing object {object_ids[i]} (class {i}) with \\\n",
        "            {len(test_images)} sample(s): {accuracy[i]:.2f}%')\n",
        "\n",
        "mean_accuracy = stat.mean(accuracy)\n",
        "print(f'Mean accuracy: {mean_accuracy:.2f}%')\n",
        "\n",
        "# For non-regression purposes\n",
        "assert mean_accuracy > 94"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
